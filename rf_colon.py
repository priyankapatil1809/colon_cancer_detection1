# -*- coding: utf-8 -*-
"""RF_Colon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-_SaTEf3SdDoYuY7BQb455Yk2hm0w-1J
"""

from google.colab import drive

drive.mount('/content/drive',timeout_ms=60000)

import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_curve, auc
from sklearn.preprocessing import StandardScaler
from skimage.feature import hog, local_binary_pattern
from skimage import color
from skimage import exposure
import seaborn as sns
import matplotlib.pyplot as plt

"""Step 1: Load Images and Labels"""

# Define your dataset directory
dataset_dir = '/content/drive/MyDrive/Colon_use'

# Initialize empty lists for images and labels
images = []
labels = []

# Define a mapping of class labels to integers
class_to_int = {'cancer_y': 0, 'cancer_n': 1}

# Loop through your dataset directory to load images and labels
for category in os.listdir(dataset_dir):
    category_dir = os.path.join(dataset_dir, category)
    for img_filename in os.listdir(category_dir):
        img_path = os.path.join(category_dir, img_filename)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (256, 256))  # Resize images to a common size
        images.append(img)  # Keep color images
        labels.append(class_to_int[category])  # Map class labels to integers

# Convert lists to NumPy arrays
images = np.array(images)
labels = np.array(labels)

"""Step 2: Define functions for Feature Extraction"""

# Define function to extract HOG features from an image
def extract_hog_features(image):
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    features = hog(image_gray, pixels_per_cell=(16, 16), cells_per_block=(2, 2), visualize=False)
    return features

# Define function to extract LBP features from an image
def extract_lbp_features(image):
    radius = 3
    n_points = 24
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    lbp_image = local_binary_pattern(image_gray, n_points, radius, method='uniform')
    lbp_histogram, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))
    lbp_histogram = lbp_histogram / (lbp_histogram.sum() + 1e-6)  # Normalize
    return lbp_histogram

def extract_color_histogram(image):
    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
    hist = hist.flatten()
    hist = hist / (hist.sum() + 1e-6)  # Normalize
    return hist

"""Step 3: Apply Feature Extraction to Each Image"""

color_hist_features_train = np.array([extract_color_histogram(img) for img in images])
hog_features_train = np.array([extract_hog_features(img) for img in images])
lbp_features_train = np.array([extract_lbp_features(img) for img in images])
rgb_features_train = images.reshape(images.shape[0], -1)  # Flatten RGB images

"""Step 4: Concatenate Features"""

X_train = np.hstack((color_hist_features_train, hog_features_train, lbp_features_train, rgb_features_train))
y_train = labels

"""Step 5: Split Data into Training and Testing Sets"""

X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

"""Step 6: Standardize Features"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""Step 7: Random Classifier and Parameters of Grid"""

# Use Random Forest Classifier
param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10],
              'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}

"""Step 8: Grid Search for Best RF parameter"""

rf_model = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
best_rf_model = grid_search.best_estimator_

"""Step 9: Make Predictions on the Test Set"""

y_pred_rf = best_rf_model.predict(X_test)

"""Step 10: Evaluate the RF Model"""

accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)

"""Step 11: Print Evaluation Results"""

print("\nResults for Random Forest:")
print("Best Parameters:", grid_search.best_params_)
print("Accuracy:", accuracy_rf)
print("Precision:", precision_rf)
print("Recall:", recall_rf)
print("F1 Score:", f1_rf)

"""Step 12: Print Confusion Mayrix for RF"""

conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
class_names = ['Cancer', 'Non-Cancer']
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_rf, annot=True, fmt="d", cmap="Blues", square=True, xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for Random Forest')
plt.show()

"""Step 13: Plot ROC Curve and calculate AUC"""

y_prob_rf = best_rf_model.predict_proba(X_test)[:, 1]
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_prob_rf)
roc_auc_value_rf = auc(fpr_rf, tpr_rf)

plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_value_rf))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for Random Forest')
plt.legend(loc='lower right')
plt.show()

# Print AUC value in the evaluation results
print("AUC:", roc_auc_value_rf)